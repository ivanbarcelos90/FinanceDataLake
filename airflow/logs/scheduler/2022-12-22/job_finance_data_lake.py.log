[2022-12-22T22:07:04.646+0000] {processor.py:154} INFO - Started process (PID=2554) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:07:04.647+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:07:04.647+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:07:04.647+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:07:05.124+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:07:05.143+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:07:05.143+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:07:05.161+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:07:05.161+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-21T22:07:05.161335+00:00, run_after=2022-12-22T22:07:05.161335+00:00
[2022-12-22T22:07:05.207+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.564 seconds
[2022-12-22T22:11:15.029+0000] {processor.py:154} INFO - Started process (PID=15324) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:11:15.029+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:11:15.030+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:11:15.030+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:11:15.505+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:11:15.521+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:11:15.521+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:11:15.536+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:11:15.536+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:11:15.576+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.550 seconds
[2022-12-22T22:11:46.084+0000] {processor.py:154} INFO - Started process (PID=16770) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:11:46.085+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:11:46.086+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:11:46.086+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:11:46.545+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:11:46.562+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:11:46.561+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:11:46.577+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:11:46.577+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:11:46.621+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.539 seconds
[2022-12-22T22:12:17.735+0000] {processor.py:154} INFO - Started process (PID=17896) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:12:17.736+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:12:17.737+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:12:17.737+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:12:18.199+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:12:18.215+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:12:18.215+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:12:18.233+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:12:18.233+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:12:18.278+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.545 seconds
[2022-12-22T22:12:49.306+0000] {processor.py:154} INFO - Started process (PID=17994) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:12:49.307+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:12:49.308+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:12:49.308+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:12:49.784+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:12:49.801+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:12:49.800+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:12:49.816+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:12:49.816+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:12:49.855+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.551 seconds
[2022-12-22T22:13:20.407+0000] {processor.py:154} INFO - Started process (PID=18093) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:13:20.408+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:13:20.409+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:13:20.409+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:13:20.876+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:13:20.892+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:13:20.891+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:13:20.908+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:13:20.908+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:13:20.952+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.548 seconds
[2022-12-22T22:13:51.203+0000] {processor.py:154} INFO - Started process (PID=18185) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:13:51.204+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:13:51.205+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:13:51.205+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:13:51.661+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:13:51.677+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:13:51.677+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:13:51.691+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:13:51.691+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:13:51.730+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.529 seconds
[2022-12-22T22:14:21.955+0000] {processor.py:154} INFO - Started process (PID=18394) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:14:21.956+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:14:21.957+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:14:21.957+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:14:22.425+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:14:22.440+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:14:22.439+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:14:22.456+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:14:22.456+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:14:22.495+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.542 seconds
[2022-12-22T22:14:52.747+0000] {processor.py:154} INFO - Started process (PID=18486) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:14:52.748+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:14:52.749+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:14:52.749+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:14:53.197+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:14:53.212+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:14:53.212+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:14:53.227+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:14:53.227+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:14:53.266+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.521 seconds
[2022-12-22T22:15:23.612+0000] {processor.py:154} INFO - Started process (PID=18580) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:15:23.613+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:15:23.614+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:15:23.613+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:15:24.060+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:15:24.076+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:15:24.075+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:15:24.091+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:15:24.091+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:15:24.132+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.522 seconds
[2022-12-22T22:15:54.431+0000] {processor.py:154} INFO - Started process (PID=18814) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:15:54.432+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:15:54.433+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:15:54.433+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:15:54.903+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:15:54.919+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:15:54.919+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:15:54.933+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:15:54.933+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:15:54.975+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.546 seconds
[2022-12-22T22:16:25.304+0000] {processor.py:154} INFO - Started process (PID=19311) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:16:25.305+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:16:25.305+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:16:25.305+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:16:25.777+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:16:25.792+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:16:25.792+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:16:25.808+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:16:25.808+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:16:25.848+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.546 seconds
[2022-12-22T22:16:56.128+0000] {processor.py:154} INFO - Started process (PID=19495) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:16:56.129+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:16:56.130+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:16:56.130+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:16:56.704+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:16:56.721+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:16:56.720+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:16:56.737+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:16:56.737+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:16:56.778+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.652 seconds
[2022-12-22T22:17:27.048+0000] {processor.py:154} INFO - Started process (PID=19795) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:17:27.049+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:17:27.049+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:17:27.049+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:17:27.508+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:17:27.525+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:17:27.524+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:17:27.540+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:17:27.540+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:17:27.584+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.539 seconds
[2022-12-22T22:17:57.864+0000] {processor.py:154} INFO - Started process (PID=19892) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:17:57.865+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:17:57.866+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:17:57.866+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:17:58.398+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:17:58.425+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:17:58.424+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:17:58.445+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:17:58.445+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:17:58.495+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.633 seconds
[2022-12-22T22:18:28.795+0000] {processor.py:154} INFO - Started process (PID=19994) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:18:28.796+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:18:28.797+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:18:28.797+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:18:29.282+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:18:29.298+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:18:29.298+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:18:29.314+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:18:29.313+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:18:29.354+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.561 seconds
[2022-12-22T22:18:59.618+0000] {processor.py:154} INFO - Started process (PID=20086) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:18:59.619+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:18:59.620+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:18:59.619+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:19:00.074+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:19:00.090+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:19:00.090+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:19:00.105+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:19:00.105+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:19:00.144+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.528 seconds
[2022-12-22T22:19:30.471+0000] {processor.py:154} INFO - Started process (PID=20603) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:19:30.472+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:19:30.473+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:19:30.473+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:19:30.913+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:19:39.240+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:19:39.241+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:19:39.317+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:19:39.391+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:19:39.383+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:19:39.394+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:19:39.413+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 8.944 seconds
[2022-12-22T22:20:09.669+0000] {processor.py:154} INFO - Started process (PID=21105) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:20:09.670+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:20:09.671+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:20:09.671+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:20:10.091+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:20:19.081+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:20:19.082+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:20:19.137+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:20:19.199+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:20:19.192+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:20:19.202+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:20:19.222+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 9.554 seconds
[2022-12-22T22:20:49.443+0000] {processor.py:154} INFO - Started process (PID=21693) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:20:49.443+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:20:49.444+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:20:49.444+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:20:49.877+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:20:57.604+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:20:57.604+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:20:57.660+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:20:57.721+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:20:57.714+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:20:57.724+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:20:57.742+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 8.302 seconds
[2022-12-22T22:21:27.930+0000] {processor.py:154} INFO - Started process (PID=22230) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:21:27.931+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:21:27.932+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:21:27.931+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:21:28.380+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:21:36.699+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:21:36.699+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:21:36.761+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:21:36.823+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:21:36.815+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:21:36.827+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:21:36.847+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 8.919 seconds
[2022-12-22T22:22:07.105+0000] {processor.py:154} INFO - Started process (PID=22720) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:22:07.106+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:22:07.107+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:22:07.107+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:22:07.532+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:22:15.341+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:22:15.342+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:22:15.397+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:22:15.458+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:22:15.450+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:22:15.460+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:22:15.481+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 8.379 seconds
[2022-12-22T22:22:45.683+0000] {processor.py:154} INFO - Started process (PID=23149) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:22:45.684+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:22:45.685+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:22:45.685+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:22:46.102+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:22:53.882+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:22:53.883+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:22:53.955+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:22:54.033+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:22:54.025+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:22:54.037+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:22:54.058+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 8.377 seconds
[2022-12-22T22:23:24.294+0000] {processor.py:154} INFO - Started process (PID=24053) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:23:24.295+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:23:24.295+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:23:24.295+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:23:24.745+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:23:32.197+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:23:32.198+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:23:32.257+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:23:32.319+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:23:32.312+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:23:32.323+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:23:32.340+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 8.049 seconds
[2022-12-22T22:24:02.571+0000] {processor.py:154} INFO - Started process (PID=24483) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:24:02.572+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:24:02.572+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:24:02.572+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:24:03.012+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:24:10.577+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:24:10.578+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:24:10.644+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:24:10.704+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:24:10.697+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:24:10.707+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:24:10.726+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 8.158 seconds
[2022-12-22T22:24:40.945+0000] {processor.py:154} INFO - Started process (PID=24919) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:24:40.946+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:24:40.947+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:24:40.946+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:24:41.397+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:24:48.904+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:24:48.905+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:24:48.964+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:24:49.024+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:24:49.018+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:24:49.028+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:24:49.047+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 8.104 seconds
[2022-12-22T22:25:19.235+0000] {processor.py:154} INFO - Started process (PID=25344) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:25:19.237+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:25:19.237+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:25:19.237+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:25:19.696+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:25:28.109+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:25:28.109+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:25:28.168+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:25:28.231+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:25:28.223+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:25:28.233+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:25:28.252+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 9.020 seconds
[2022-12-22T22:25:58.524+0000] {processor.py:154} INFO - Started process (PID=25791) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:25:58.524+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:25:58.525+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:25:58.525+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:25:58.959+0000] {logging_mixin.py:137} INFO - Download object from s3 bucket...
[2022-12-22T22:26:07.886+0000] {logging_mixin.py:137} INFO - Dataframe created succefully from s3 object!
[2022-12-22T22:26:07.887+0000] {logging_mixin.py:137} INFO - Starting cleanning proccess...
[2022-12-22T22:26:07.943+0000] {logging_mixin.py:137} INFO - Cleanning proccess completed succeffully!
[2022-12-22T22:26:08.004+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:26:07.998+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 96, in <module>
    cleanning_data(bronze_bucket)
  File "/workspace/finance_data_lake/app_cleanning.py", line 43, in cleanning_data
    df_clean_2 = (df_clean.withColumn('year', year('Date'))
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/dataframe.py", line 3036, in withColumn
    return DataFrame(self._jdf.withColumn(colName, col._jc), self.sparkSession)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/py4j/java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: cannot resolve 'year(Date)' due to data type mismatch: argument 1 requires date type, however, 'Date' is of int type.;
'Project [Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8, year(Date#0) AS year#28]
+- Filter atleastnnonnulls(9, Date#0, Open#1, High#2, Low#3, Close#4, Adj Close#5, Volume#6, ticker#7, Event#8)
   +- Relation [Date#0,Open#1,High#2,Low#3,Close#4,Adj Close#5,Volume#6,ticker#7,Event#8] parquet
[2022-12-22T22:26:08.007+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:26:08.026+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 9.505 seconds
[2022-12-22T22:26:38.211+0000] {processor.py:154} INFO - Started process (PID=26235) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:26:38.212+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:26:38.213+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:26:38.213+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:26:38.750+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:26:38.795+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:26:38.795+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:26:38.812+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:26:38.811+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:26:38.881+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.672 seconds
[2022-12-22T22:27:09.079+0000] {processor.py:154} INFO - Started process (PID=26570) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:27:09.081+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:27:09.081+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:27:09.081+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:27:09.615+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:27:09.634+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:27:09.633+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:27:09.651+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:27:09.651+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:27:09.692+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.616 seconds
[2022-12-22T22:27:39.967+0000] {processor.py:154} INFO - Started process (PID=27092) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:27:39.968+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:27:39.969+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:27:39.969+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:27:40.437+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:27:40.454+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:27:40.453+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:27:40.469+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:27:40.469+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:27:40.510+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.545 seconds
[2022-12-22T22:28:10.723+0000] {processor.py:154} INFO - Started process (PID=27184) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:28:10.723+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:28:10.724+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:28:10.724+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:28:11.178+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:28:11.196+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:28:11.195+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:28:11.211+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:28:11.211+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:28:11.251+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.531 seconds
[2022-12-22T22:28:41.482+0000] {processor.py:154} INFO - Started process (PID=27278) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:28:41.483+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:28:41.484+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:28:41.483+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:28:41.931+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:28:41.947+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:28:41.947+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:28:41.962+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:28:41.962+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:28:42.003+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.523 seconds
[2022-12-22T22:29:12.241+0000] {processor.py:154} INFO - Started process (PID=27370) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:29:12.242+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:29:12.243+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:29:12.243+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:29:12.691+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:29:12.706+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:29:12.706+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:29:12.720+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:29:12.720+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:29:12.761+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.522 seconds
[2022-12-22T22:29:43.001+0000] {processor.py:154} INFO - Started process (PID=27464) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:29:43.001+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:29:43.002+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:29:43.002+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:29:43.486+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:29:43.502+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:29:43.502+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:29:43.517+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:29:43.517+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:29:43.556+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.558 seconds
[2022-12-22T22:30:13.757+0000] {processor.py:154} INFO - Started process (PID=27556) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:30:13.758+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:30:13.759+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:30:13.759+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:30:14.205+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:30:14.219+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:30:14.219+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:30:14.234+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:30:14.234+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:30:14.272+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.518 seconds
[2022-12-22T22:30:44.519+0000] {processor.py:154} INFO - Started process (PID=27650) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:30:44.520+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:30:44.520+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:30:44.520+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:30:44.995+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:30:45.010+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:30:45.009+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:30:45.025+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:30:45.025+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:30:45.065+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.549 seconds
[2022-12-22T22:31:15.270+0000] {processor.py:154} INFO - Started process (PID=27742) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:31:15.270+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:31:15.271+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:31:15.271+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:31:15.733+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:31:15.749+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:31:15.749+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:31:15.765+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:31:15.764+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:31:15.803+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.536 seconds
[2022-12-22T22:31:46.031+0000] {processor.py:154} INFO - Started process (PID=27836) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:31:46.032+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:31:46.032+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:31:46.032+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:31:46.527+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:31:46.546+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:31:46.545+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:31:46.562+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:31:46.562+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:31:46.614+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.586 seconds
[2022-12-22T22:32:16.799+0000] {processor.py:154} INFO - Started process (PID=27987) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:32:16.799+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:32:16.800+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:32:16.800+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:32:17.279+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:32:17.295+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:32:17.294+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:32:17.310+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:32:17.309+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:32:17.349+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.553 seconds
[2022-12-22T22:32:47.560+0000] {processor.py:154} INFO - Started process (PID=28081) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:32:47.561+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:32:47.562+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:32:47.562+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:32:48.022+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:32:48.017+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 11, in <module>
    bronze_bucket = Variable.get(BRONZE_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-bronze does not exist'
[2022-12-22T22:32:48.023+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:32:48.041+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.483 seconds
[2022-12-22T22:33:18.244+0000] {processor.py:154} INFO - Started process (PID=28177) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:33:18.245+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:33:18.246+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:33:18.246+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:33:18.706+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:33:18.701+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 11, in <module>
    bronze_bucket = Variable.get(BRONZE_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-bronze does not exist'
[2022-12-22T22:33:18.708+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:33:18.725+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.483 seconds
[2022-12-22T22:33:48.909+0000] {processor.py:154} INFO - Started process (PID=28273) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:33:48.910+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:33:48.910+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:33:48.910+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:33:49.409+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:33:49.403+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 11, in <module>
    bronze_bucket = Variable.get(BRONZE_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-bronze does not exist'
[2022-12-22T22:33:49.410+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:33:49.428+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.523 seconds
[2022-12-22T22:34:19.685+0000] {processor.py:154} INFO - Started process (PID=28374) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:34:19.685+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:34:19.686+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:34:19.686+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:34:20.143+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:34:20.135+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 11, in <module>
    bronze_bucket = Variable.get(BRONZE_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-bronze does not exist'
[2022-12-22T22:34:20.145+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:34:20.174+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.492 seconds
[2022-12-22T22:34:50.346+0000] {processor.py:154} INFO - Started process (PID=28466) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:34:50.347+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:34:50.348+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:34:50.348+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:34:50.819+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:34:50.815+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 11, in <module>
    bronze_bucket = Variable.get(BRONZE_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-bronze does not exist'
[2022-12-22T22:34:50.820+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:34:50.841+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.498 seconds
[2022-12-22T22:35:21.122+0000] {processor.py:154} INFO - Started process (PID=28560) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:35:21.123+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:35:21.123+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:35:21.123+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:35:21.568+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:35:21.563+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_cleanning.py", line 11, in <module>
    bronze_bucket = Variable.get(BRONZE_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-bronze does not exist'
[2022-12-22T22:35:21.569+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:35:21.585+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.466 seconds
[2022-12-22T22:35:51.776+0000] {processor.py:154} INFO - Started process (PID=28654) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:35:51.777+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:35:51.777+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:35:51.777+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:35:52.291+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:35:52.285+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_gold.py", line 7, in <module>
    silver_bucket = Variable.get(SILVER_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-silver does not exist'
[2022-12-22T22:35:52.292+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:35:52.309+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.536 seconds
[2022-12-22T22:36:22.528+0000] {processor.py:154} INFO - Started process (PID=28748) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:36:22.529+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:36:22.530+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:36:22.530+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:36:22.994+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:36:22.990+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_gold.py", line 7, in <module>
    silver_bucket = Variable.get(SILVER_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-silver does not exist'
[2022-12-22T22:36:22.995+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:36:23.013+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.487 seconds
[2022-12-22T22:36:53.181+0000] {processor.py:154} INFO - Started process (PID=28850) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:36:53.182+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:36:53.183+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:36:53.183+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:36:53.705+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:36:53.699+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_gold.py", line 7, in <module>
    silver_bucket = Variable.get(SILVER_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-silver does not exist'
[2022-12-22T22:36:53.706+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:36:53.724+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.545 seconds
[2022-12-22T22:37:23.945+0000] {processor.py:154} INFO - Started process (PID=29018) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:37:23.946+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:37:23.947+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:37:23.946+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:37:24.455+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:37:24.449+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_gold.py", line 7, in <module>
    silver_bucket = Variable.get(SILVER_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-silver does not exist'
[2022-12-22T22:37:24.457+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:37:24.479+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.536 seconds
[2022-12-22T22:37:54.723+0000] {processor.py:154} INFO - Started process (PID=29112) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:37:54.724+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:37:54.725+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:37:54.725+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:37:55.219+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:37:55.213+0000] {dagbag.py:342} ERROR - Failed to import: /workspace/airflow/dags/job_finance_data_lake.py
Traceback (most recent call last):
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/workspace/airflow/dags/job_finance_data_lake.py", line 3, in <module>
    import app_raw, app_cleanning, app_gold, create_bucket
  File "/workspace/finance_data_lake/app_gold.py", line 7, in <module>
    silver_bucket = Variable.get(SILVER_ZONE)
  File "/root/.local/share/virtualenvs/workspace-dqq3IVyd/lib/python3.10/site-packages/airflow/models/variable.py", line 141, in get
    raise KeyError(f'Variable {key} does not exist')
KeyError: 'Variable finance-data-lake-silver does not exist'
[2022-12-22T22:37:55.220+0000] {processor.py:768} WARNING - No viable dags retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:37:55.239+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.519 seconds
[2022-12-22T22:38:25.496+0000] {processor.py:154} INFO - Started process (PID=29707) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:38:25.496+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:38:25.497+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:38:25.497+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:38:25.980+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:38:26.029+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:38:26.029+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:38:26.049+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:38:26.049+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:38:26.112+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.619 seconds
[2022-12-22T22:38:56.379+0000] {processor.py:154} INFO - Started process (PID=29832) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:38:56.380+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:38:56.381+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:38:56.381+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:38:56.887+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:38:56.904+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:38:56.904+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:38:56.923+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:38:56.923+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:38:56.965+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.588 seconds
[2022-12-22T22:39:27.151+0000] {processor.py:154} INFO - Started process (PID=29926) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:39:27.152+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:39:27.154+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:39:27.154+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:39:27.716+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:39:27.733+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:39:27.732+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:39:27.748+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:39:27.748+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:39:27.789+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.641 seconds
[2022-12-22T22:39:58.026+0000] {processor.py:154} INFO - Started process (PID=30683) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:39:58.027+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:39:58.027+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:39:58.027+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:39:58.529+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:39:58.544+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:39:58.543+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:39:58.558+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:39:58.558+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:39:58.599+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.575 seconds
[2022-12-22T22:40:28.789+0000] {processor.py:154} INFO - Started process (PID=30779) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:40:28.790+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:40:28.790+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:40:28.790+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:40:29.247+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:40:29.262+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:40:29.262+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:40:29.275+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:40:29.275+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:40:29.313+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.527 seconds
[2022-12-22T22:40:59.555+0000] {processor.py:154} INFO - Started process (PID=30871) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:40:59.556+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:40:59.557+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:40:59.556+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:41:00.054+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:41:00.070+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:41:00.069+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:41:00.085+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:41:00.085+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:41:00.123+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.571 seconds
[2022-12-22T22:41:30.322+0000] {processor.py:154} INFO - Started process (PID=31478) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:41:30.323+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:41:30.324+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:41:30.324+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:41:30.836+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:41:30.853+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:41:30.852+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:41:30.871+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:41:30.871+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:41:30.914+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.594 seconds
[2022-12-22T22:51:15.639+0000] {processor.py:154} INFO - Started process (PID=16656) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:51:15.640+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:51:15.641+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:51:15.641+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:51:16.105+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:51:16.121+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:51:16.121+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:51:16.138+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:51:16.138+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:51:16.178+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.542 seconds
[2022-12-22T22:51:55.455+0000] {processor.py:154} INFO - Started process (PID=18043) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:51:55.456+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:51:55.456+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:51:55.456+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:51:55.930+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:51:55.945+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:51:55.945+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:51:55.959+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:51:55.959+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:51:56.001+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.548 seconds
[2022-12-22T22:52:26.964+0000] {processor.py:154} INFO - Started process (PID=18194) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:52:26.965+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:52:26.966+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:52:26.966+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:52:27.419+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:52:27.435+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:52:27.434+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:52:27.449+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:52:27.449+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:52:27.502+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.541 seconds
[2022-12-22T22:52:58.520+0000] {processor.py:154} INFO - Started process (PID=18293) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:52:58.521+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:52:58.521+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:52:58.521+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:52:58.986+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:52:59.002+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:52:59.001+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:52:59.017+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:52:59.016+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:52:59.056+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.539 seconds
[2022-12-22T22:53:30.100+0000] {processor.py:154} INFO - Started process (PID=18387) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:53:30.101+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:53:30.102+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:53:30.102+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:53:30.567+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:53:30.584+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:53:30.583+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:53:30.601+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:53:30.601+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:53:30.641+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.543 seconds
[2022-12-22T22:54:01.684+0000] {processor.py:154} INFO - Started process (PID=18693) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:54:01.685+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:54:01.686+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:54:01.686+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:54:02.143+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:54:02.158+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:54:02.157+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:54:02.173+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:54:02.173+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:54:02.212+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.530 seconds
[2022-12-22T22:54:33.042+0000] {processor.py:154} INFO - Started process (PID=18817) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:54:33.042+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:54:33.043+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:54:33.043+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:54:33.528+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:54:33.544+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:54:33.543+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:54:33.557+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:54:33.557+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:54:33.599+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.560 seconds
[2022-12-22T22:55:04.191+0000] {processor.py:154} INFO - Started process (PID=18968) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:55:04.192+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:55:04.193+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:55:04.193+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:55:04.644+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:55:04.662+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:55:04.661+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:55:04.677+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:55:04.677+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:55:04.714+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.525 seconds
[2022-12-22T22:55:35.332+0000] {processor.py:154} INFO - Started process (PID=19062) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:55:35.333+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:55:35.333+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:55:35.333+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:55:35.779+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:55:35.795+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:55:35.794+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:55:35.810+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:55:35.810+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:55:35.847+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.518 seconds
[2022-12-22T22:56:06.446+0000] {processor.py:154} INFO - Started process (PID=19154) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:56:06.447+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:56:06.448+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:56:06.448+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:56:06.898+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:56:06.915+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:56:06.914+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:56:06.930+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:56:06.930+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:56:06.968+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.524 seconds
[2022-12-22T22:56:37.257+0000] {processor.py:154} INFO - Started process (PID=19363) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:56:37.258+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:56:37.259+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:56:37.259+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:56:37.742+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:56:37.758+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:56:37.758+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:56:37.774+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:56:37.774+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:56:37.816+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.561 seconds
[2022-12-22T22:57:08.076+0000] {processor.py:154} INFO - Started process (PID=19514) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:57:08.077+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:57:08.078+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:57:08.078+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:57:08.594+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:57:08.610+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:57:08.609+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:57:08.626+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:57:08.626+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:57:08.670+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.596 seconds
[2022-12-22T22:57:39.011+0000] {processor.py:154} INFO - Started process (PID=19608) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:57:39.012+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:57:39.013+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:57:39.013+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:57:39.520+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:57:39.540+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:57:39.539+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:57:39.559+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:57:39.558+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:57:39.604+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.595 seconds
[2022-12-22T22:58:09.941+0000] {processor.py:154} INFO - Started process (PID=19700) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:58:09.942+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:58:09.943+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:58:09.943+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:58:10.430+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:58:10.447+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:58:10.446+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:58:10.464+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:58:10.463+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:58:10.507+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.568 seconds
[2022-12-22T22:58:40.765+0000] {processor.py:154} INFO - Started process (PID=19800) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:58:40.766+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:58:40.767+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:58:40.767+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:58:41.223+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:58:41.240+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:58:41.239+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:58:41.255+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:58:41.255+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:58:41.295+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.532 seconds
[2022-12-22T22:59:11.580+0000] {processor.py:154} INFO - Started process (PID=19986) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:59:11.580+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:59:11.581+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:59:11.581+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:59:12.034+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:59:12.050+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:59:12.049+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:59:12.064+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:59:12.064+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:59:12.103+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.526 seconds
[2022-12-22T22:59:42.346+0000] {processor.py:154} INFO - Started process (PID=20080) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:59:42.347+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T22:59:42.347+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:59:42.347+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:59:42.816+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T22:59:42.833+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:59:42.832+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T22:59:42.849+0000] {logging_mixin.py:137} INFO - [2022-12-22T22:59:42.848+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T22:59:42.889+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.546 seconds
[2022-12-22T23:00:13.156+0000] {processor.py:154} INFO - Started process (PID=20173) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:00:13.157+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T23:00:13.157+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:00:13.157+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:00:13.652+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:00:13.671+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:00:13.671+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T23:00:13.691+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:00:13.691+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T23:00:13.731+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.578 seconds
[2022-12-22T23:00:43.908+0000] {processor.py:154} INFO - Started process (PID=20268) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:00:43.909+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T23:00:43.910+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:00:43.909+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:00:44.366+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:00:44.382+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:00:44.381+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T23:00:44.396+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:00:44.396+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T23:00:44.434+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.528 seconds
[2022-12-22T23:01:14.665+0000] {processor.py:154} INFO - Started process (PID=20360) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:01:14.666+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T23:01:14.667+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:01:14.667+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:01:15.133+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:01:15.149+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:01:15.149+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T23:01:15.165+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:01:15.165+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T23:01:15.207+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.543 seconds
[2022-12-22T23:01:45.431+0000] {processor.py:154} INFO - Started process (PID=20716) to work on /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:01:45.432+0000] {processor.py:756} INFO - Processing file /workspace/airflow/dags/job_finance_data_lake.py for tasks to queue
[2022-12-22T23:01:45.433+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:01:45.433+0000] {dagbag.py:537} INFO - Filling up the DagBag from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:01:45.901+0000] {processor.py:766} INFO - DAG(s) dict_keys(['finance_data_lake']) retrieved from /workspace/airflow/dags/job_finance_data_lake.py
[2022-12-22T23:01:45.915+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:01:45.915+0000] {dag.py:2585} INFO - Sync 1 DAGs
[2022-12-22T23:01:45.930+0000] {logging_mixin.py:137} INFO - [2022-12-22T23:01:45.930+0000] {dag.py:3336} INFO - Setting next_dagrun for finance_data_lake to 2022-12-22T22:07:05.161335+00:00, run_after=2022-12-23T22:07:05.161335+00:00
[2022-12-22T23:01:45.970+0000] {processor.py:176} INFO - Processing /workspace/airflow/dags/job_finance_data_lake.py took 0.542 seconds
